{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook: Funciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://oci02.img.iteso.mx/identidad_de_instancia_2018/ITESO/Logos%20ITESO/Logo-ITESO-Principal.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font color= #004A94> <font size = 6> Msc Ciencia de datos </font> <br> <br> <font color= #047CFB> <font size = 4>I.F. Juan Francisco Muñoz Elguezabal - franciscome@iteso.mx </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color= #004A94> <font size = 6> ANÁLISIS ESTADÍSTICO MULTIVARIABLE </font> <br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color=#42c29b><font size=5> Una comparación entre modelos regresivos lineales y clustering secuencial como predictores de series de tiempo financieras </font> <br> <br>\n",
    "\n",
    "<center><font color=#047CFB><font size=5> El caso  de una estrategia de trading para el mercado internacional de divisas </font> <br> <br> \n",
    "    \n",
    "<center> <font color= #047CFB> <font size = 4> Repositorio: <a href='https://github.com/IFFranciscoME/FinTechLab/tree/master/'>Link</a></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#004A94\"> Cargar librerías </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                     # funciones numericas\n",
    "import pandas as pd                                    # dataframes y utilidades\n",
    "from statsmodels.tsa.api import acf, pacf              # funciones de econometria\n",
    "from statsmodels.formula.api import ols                # herramientas estadisticas: modelo lineal con ols\n",
    "from sklearn.preprocessing import StandardScaler       # estandarizacion de variables\n",
    "from sklearn.decomposition import PCA                  # analisis de componentes principales (PCA)\n",
    "import statsmodels.api as sm                           # utilidades para modelo regresion lineal\n",
    "from sklearn.model_selection import train_test_split   # separacion de conjunto de entrenamiento y prueba\n",
    "from sklearn.metrics import mean_squared_error         # error cuadratico medio\n",
    "\n",
    "import mass_ts as mts                                  # Clustering para series de tiempo\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='mass_ts')\n",
    "\n",
    "pd.set_option('display.max_rows', None)                # sin limite de renglones maximos para mostrar pandas\n",
    "pd.set_option('display.max_columns', None)             # sin limite de columnas maximas para mostrar pandas\n",
    "pd.set_option('display.width', None)                   # sin limite el ancho del display\n",
    "pd.set_option('display.expand_frame_repr', False)      # visualizar todas las columnas de un dataframe\n",
    "pd.options.mode.chained_assignment = None              # para evitar el warning enfadoso de indexacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#004A94\"> FUNCION: STSC - MASS </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ------------------------------------------------------------------------------- FUNCION: STSC - MASS -- #\n",
    "# -- ------------------------------------------------------------------------------------ Version manual -- #\n",
    "\n",
    "def f_stsc_mass(p_precios, p_calendario, p_ventana):\n",
    "    \"\"\"\n",
    "    :param: p_precios : dataframe : precios OHLC para crear una serie\n",
    "    :param: p_calendario : dataframe :\n",
    "    :param: p_indicadores : dataframe :\n",
    "    :param: p_ventana : int :\n",
    "\n",
    "    :return:\n",
    "\n",
    "    p_precios = df_pe_m1\n",
    "    p_indicadores = res3_anova\n",
    "    p_calendario = df_ce_w\n",
    "    p_ventana = 30\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # de la serie de precios completa de 1 minuto, tomando una sub-serie de ventana T de la reacción\n",
    "    # del precio ante el comunicado de un indicador que paso la prueba de autoanova, quiero saber si\n",
    "    # hubo otras veces donde se repitió el mismo patrón y si las hubo, que sean de inmediato posterior\n",
    "    # a las fechas cercanas al comunicado del indicador en otras fechas.\n",
    "\n",
    "    fechas = list()\n",
    "    sub_datos = p_calendario\n",
    "\n",
    "    # buscar motifs en todas las fechas en las que se publico el indicador y dio el escenario\n",
    "    # aprobado por anova\n",
    "\n",
    "    for i in range(0, len(sub_datos['timestamp'])):\n",
    "        # print('buscando patrones para: ' + indicador + ' en ' + str(sub_datos['timestamp'][i]))\n",
    "\n",
    "        # fecha inicial de serie query es un evento arbitrario del calendario\n",
    "        fecha_ini = sub_datos['timestamp'][i]\n",
    "        # se toma el timestamp de precios igual a timestamp del primer escenario del indicador\n",
    "        ind_ini = np.where(p_precios['timestamp'] == fecha_ini)[0]\n",
    "        # fecha final es la fecha inicial mas un tamaño de ventana arbitrario\n",
    "        ind_fin = ind_ini + p_ventana\n",
    "        # se construye la serie query\n",
    "        serie_q = p_precios.iloc[ind_ini[0]:ind_fin[0], :]\n",
    "        # serie_q = np.array((serie_q['close'] - serie_q['open']) * 10000)\n",
    "        serie_q = np.array(serie_q['close'])\n",
    "        serie_q = serie_q/max(serie_q)\n",
    "\n",
    "        # se construye la serie de busqueda (un array de numpy de 1 dimension)\n",
    "        serie = np.array(p_precios['close'])[7:]\n",
    "        serie = serie/max(serie)\n",
    "\n",
    "        # parametros del algoritmo\n",
    "        # tamaño de ventana para iterar la busqueda = tamaño de query\n",
    "        batch_size = p_ventana*100\n",
    "        # regresar los Top X casos que \"mas se parezcan\" = Cantidad total de publicaciones de indicador\n",
    "        top_matches = 100\n",
    "        # regresar los indices y las distancias\n",
    "        mass_indices, mass_dists = mts.mass2_batch(serie, serie_q, batch_size=batch_size,\n",
    "                                                   top_matches=top_matches, n_jobs=3)\n",
    "\n",
    "        # obtener las fechas de los indices regresados fecha inicial del motif detectado y\n",
    "        # fecha final segun amplitud p_ventana.\n",
    "        mass_fechas = [p_precios['timestamp'][mass_indices[i]] for i in range(0, len(mass_indices))]\n",
    "\n",
    "        # cada cada fecha propuesta por el MASS como fecha inicial de un motif con similitud, revisar si\n",
    "        # esta fecha propuesta coincide con otra fecha de publicación de indicador con el mismo escenario\n",
    "        fecha_encontrada = list()\n",
    "        for k in range(0, len(mass_fechas)):\n",
    "            encuentros = [i for i, j in enumerate(list(sub_datos['timestamp'])) if j == mass_fechas[k]]\n",
    "            if len(encuentros) != 0 and mass_fechas[k] != fecha_ini:\n",
    "                fecha_encontrada.append(mass_fechas[k])  # mismo patron entre precios y serie_q con mass\n",
    "\n",
    "        fechas.append(fecha_encontrada)\n",
    "\n",
    "    return fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#004A94\"> FUNCION: Clasificacion de escenarios de indicador </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ------------------------------------------------- FUNCION: Clasificacion de escenarios de indicador -- #\n",
    "# -- ------------------------------------------------------------------------------------ Version manual -- #\n",
    "\n",
    "def f_escenario(p0_datos):\n",
    "    \"\"\"\n",
    "    :param: pd.DataFrame : DataFrame : calendario economico con columnas: timestamp, name,\n",
    "                                                                     actual, consensus, previous\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    datos = p0_datos\n",
    "\n",
    "    # criterio para rellenar datos faltantes 'nan'\n",
    "    # cuando falta en consensus\n",
    "    nan_consensus = datos.index[np.isnan(datos['consensus'])].tolist()\n",
    "\n",
    "    # asignarle a consensus lo que tiene previous\n",
    "    datos['consensus'][nan_consensus] = datos['previous'][nan_consensus]\n",
    "\n",
    "    # inicializar la columna escenario, habra los siguientes: A, B, C, D\n",
    "    datos['escenario'] = 'X'\n",
    "\n",
    "    # -- -- A: actual >= previous & actual >= consensus & consensus >= previous\n",
    "    datos['escenario'][((datos['actual'] >= datos['previous']) &\n",
    "                        (datos['actual'] >= datos['consensus']))] = 'A'\n",
    "\n",
    "    # -- -- B: actual >= previous & actual >= consensus & consensus < Precious\n",
    "    datos['escenario'][((datos['actual'] >= datos['previous']) &\n",
    "                        (datos['actual'] < datos['consensus']))] = 'B'\n",
    "\n",
    "    # -- -- C: actual >= previous & actual < consensus & consensus >= previous\n",
    "    datos['escenario'][((datos['actual'] < datos['previous']) &\n",
    "                        (datos['actual'] >= datos['consensus']))] = 'C'\n",
    "\n",
    "    # -- -- D: actual >= previous & actual < consensus & consensus < previous\n",
    "    datos['escenario'][((datos['actual'] < datos['previous']) &\n",
    "                        (datos['actual'] < datos['consensus']))] = 'D'\n",
    "\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#004A94\"> FUNCION: Generacion de variables ENDOGENAS series de tiempo </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- --------------------------------------- FUNCION: Generacion de variables ENDOGENAS series de tiempo -- #\n",
    "# -- ------------------------------------------------------------------------------------ Version manual -- #\n",
    "\n",
    "def f_features_end(p_datos):\n",
    "    \"\"\"\n",
    "    :param p_datos: pd.DataFrae : dataframe con 5 columnas 'timestamp', 'open', 'high', 'low', 'close'\n",
    "    :return: r_features : dataframe con 5 columnas, nombres cohercionados + Features generados\n",
    "\n",
    "    # Debuging\n",
    "    p_datos = df_precios\n",
    "    p_datos = pd.DataFrame({''timestamp': {}, 'open': np.random.normal(1.1400, 0.0050, 20).\n",
    "                                              'high': np.random.normal(1.1400, 0.0050, 20),\n",
    "                                              'low': np.random.normal(1.1400, 0.0050, 20),\n",
    "                                              'close': np.random.normal(1.1400, 0.0050, 20)})\n",
    "    \"\"\"\n",
    "\n",
    "    datos = p_datos\n",
    "    datos.columns = ['timestamp', 'open', 'high', 'low', 'close']\n",
    "\n",
    "    cols = list(datos.columns)[1:]\n",
    "    datos[cols] = datos[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # formato columna timestamp como 'datetime'\n",
    "    datos['timestamp'] = pd.to_datetime(datos['timestamp'])\n",
    "    # datos['timestamp'] = datos['timestamp'].dt.tz_localize('UTC')\n",
    "\n",
    "    # rendimiento logaritmico de ventana 1\n",
    "    datos['logrend'] = np.log(datos['close']/datos['close'].shift(1)).dropna()\n",
    "\n",
    "    # pips descontados al cierre\n",
    "    datos['co'] = (datos['close']-datos['open'])*10000\n",
    "\n",
    "    # pips descontados alcistas\n",
    "    datos['ho'] = (datos['high'] - datos['open'])*10000\n",
    "\n",
    "    # pips descontados bajistas\n",
    "    datos['ol'] = (datos['open'] - datos['low'])*10000\n",
    "\n",
    "    # pips descontados en total (medida de volatilidad)\n",
    "    datos['hl'] = (datos['high'] - datos['low'])*10000\n",
    "\n",
    "    # funciones de ACF y PACF para determinar ancho de ventana historica\n",
    "    data_acf = acf(datos['logrend'].dropna(), nlags=12, fft=True)\n",
    "    data_pac = pacf(datos['logrend'].dropna(), nlags=12)\n",
    "    sig = round(1.96/np.sqrt(len(datos['logrend'])), 4)\n",
    "\n",
    "    # componentes AR y MA\n",
    "    maxs = list(set(list(np.where((data_pac > sig) | (data_pac < -sig))[0]) +\n",
    "                    list(np.where((data_acf > sig) | (data_acf < -sig))[0])))\n",
    "    # encontrar la componente maxima como indicativo de informacion historica autorelacionada\n",
    "    max_n = maxs[np.argmax(maxs)]\n",
    "\n",
    "    # condicion arbitraria: 5 resagos minimos para calcular variables moviles\n",
    "    if max_n <= 2:\n",
    "        max_n = 5\n",
    "\n",
    "    # ciclo para calcular N features con logica de \"Ventanas de tamaño n\"\n",
    "    for n in range(0, max_n):\n",
    "\n",
    "        # resago n de ho\n",
    "        datos['lag_ho_' + str(n + 1)] = np.log(datos['ho'].shift(n + 1))\n",
    "\n",
    "        # resago n de ol\n",
    "        datos['lag_ol_' + str(n + 1)] = np.log(datos['ol'].shift(n + 1))\n",
    "\n",
    "        # promedio movil de ventana n\n",
    "        datos['ma_ol_' + str(n + 2)] = datos['ol'].rolling(n + 2).mean()\n",
    "\n",
    "        # promedio movil de ventana n\n",
    "        datos['ma_ho_' + str(n + 2)] = datos['ho'].rolling(n + 2).mean()\n",
    "\n",
    "    # asignar timestamp como index\n",
    "    datos.index = pd.to_datetime(datos['timestamp'])\n",
    "    # quitar columnas no necesarias para modelos de ML\n",
    "    datos = datos.drop(['timestamp', 'open', 'high', 'low', 'close', 'hl', 'logrend'], axis=1)\n",
    "    # borrar columnas donde exista solo NAs\n",
    "    r_features = datos.dropna(axis='columns', how='all')\n",
    "    # borrar renglones donde exista algun NA\n",
    "    r_features = r_features.dropna(axis='rows')\n",
    "    # convertir a numeros tipo float las columnas\n",
    "    r_features.iloc[:, 1:] = r_features.iloc[:, 1:].astype(float)\n",
    "    # estandarizacion de todas las variables independientes\n",
    "    lista = r_features[list(r_features.columns[1:])]\n",
    "    r_features[list(r_features.columns[1:])] = StandardScaler().fit_transform(lista)\n",
    "\n",
    "    return r_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#004A94\"> FUNCION: Ajustar RLM a datos </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ---------------------------------------------------------------------- FUNCION: Ajustar RLM a datos -- #\n",
    "# -- ---------------------------------------------------------------------- ---------------------------- -- #\n",
    "\n",
    "def f_rlm(p_datos, p_y):\n",
    "    \"\"\"\n",
    "    :param p_datos: pd.DataFrame : DataFrame con variable \"y\" (1era col), y n variables \"x_n\" (2:n)\n",
    "    :param p_y : str : nombre de la columna a elegir como variable dependiente Y\n",
    "    :return:\n",
    "    p_datos = df_datos\n",
    "    \"\"\"\n",
    "\n",
    "    datos = p_datos\n",
    "\n",
    "    # Reacomodar los datos como arreglos\n",
    "    y_multiple = np.array(datos[p_y])\n",
    "    x_multiple = np.array(datos.iloc[:, 1:])\n",
    "\n",
    "    # datos para entrenamiento y prueba\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x_multiple, y_multiple, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Agregar interceptos a X en entrenamiento y prueba\n",
    "    train_x_betha = sm.add_constant(train_x)\n",
    "    test_x_betha = sm.add_constant(test_x)\n",
    "\n",
    "    # Modelo ajustado (entrenamiento)\n",
    "    modelo_train = sm.OLS(train_y, train_x_betha)\n",
    "    # Resultados de ajuste de modelo (entrenamiento)\n",
    "    modelo_fit_train = modelo_train.fit()\n",
    "\n",
    "    # Modelo ajustado (prueba)\n",
    "    modelo_test = sm.OLS(test_y, test_x_betha)\n",
    "    # Resultados de ajuste de modelo (prueba)\n",
    "    modelo_fit_test = modelo_test.fit()\n",
    "\n",
    "    # -- -------------------------------------------------------------------- Con datos de ENTRENAMIENTO -- #\n",
    "    # modelo completo resultante\n",
    "    r_train_modelo = modelo_fit_train\n",
    "    # DataFrame con nombre de parametros segun dataset, nombre de parametros y pvalues segun modelo\n",
    "    r_df_train = pd.DataFrame({'df_params': ['intercepto'] + list(datos.columns[1:]),\n",
    "                               'm_params': r_train_modelo.model.data.param_names,\n",
    "                               'pv_params': r_train_modelo.pvalues})\n",
    "    # valor de AIC del modelo\n",
    "    r_train_aic = r_train_modelo.aic\n",
    "    # valor de BIC del modelo\n",
    "    r_train_bic = r_train_modelo.bic\n",
    "\n",
    "    # -- --------------------------------------------------------------------------- Con datos de PRUEBA -- #\n",
    "    # modelo completo resultante\n",
    "    r_test_modelo = modelo_fit_test\n",
    "    # DataFrame con nombre de parametros segun dataset, nombre de parametros y pvalues segun modelo\n",
    "    r_df_test = pd.DataFrame({'df_params': ['intercepto'] + list(datos.columns[1:]),\n",
    "                              'm_params': r_test_modelo.model.data.param_names,\n",
    "                              'pv_params': r_test_modelo.pvalues})\n",
    "    # valor de AIC del modelo\n",
    "    r_test_aic = r_test_modelo.aic\n",
    "    # valor de BIC del modelo\n",
    "    r_test_bic = r_test_modelo.bic\n",
    "\n",
    "    # tabla de resultados periodo de entrenamiento\n",
    "    r_df_pred_train = pd.DataFrame({'y': train_y, 'y_ajustada': modelo_fit_train.predict()})\n",
    "    # tabla de resultados periodo de prueba\n",
    "    r_df_pred_test = pd.DataFrame({'y': test_y, 'y_ajustada': modelo_fit_test.predict()})\n",
    "    # Errores cuadraticos medios para entrenamiento y prueba\n",
    "    mse_train = round(mean_squared_error(r_df_pred_train['y'], r_df_pred_train['y_ajustada']), 2)\n",
    "    mse_test = round(mean_squared_error(r_df_pred_test['y'], r_df_pred_test['y_ajustada']), 2)\n",
    "\n",
    "    # -- --------------------------------------------------------------------------------- Datos finales -- #\n",
    "    df_rlm = pd.DataFrame({'conjunto': ['train', 'test'],\n",
    "                           'aic': [round(r_train_aic, 2), round(r_test_aic, 2)],\n",
    "                           'bic': [round(r_train_bic, 2), round(r_test_bic, 2)],\n",
    "                           'params': [len(r_df_train), len(r_df_test)],\n",
    "                           'mse': [mse_train, mse_test],\n",
    "                           'r2': [round(r_train_modelo.rsquared, 4), round(r_test_modelo.rsquared, 4)]})\n",
    "\n",
    "    return df_rlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#004A94\"> FUNCION: Aplicar PCA a datos </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ---------------------------------------------------------------------- FUNCION: Aplicar PCA a datos -- #\n",
    "# -- ---------------------------------------------------------------------- ---------------------------- -- #\n",
    "\n",
    "def f_pca(p_datos, p_exp):\n",
    "    \"\"\"\n",
    "    :param p_datos:\n",
    "    :param p_exp:\n",
    "    :return:\n",
    "\n",
    "    p_datos = df_datos\n",
    "    p_exp = .90\n",
    "    \"\"\"\n",
    "    datos = p_datos\n",
    "\n",
    "    pca = PCA(n_components=10)\n",
    "    datos_pca = datos.iloc[:, 1:]\n",
    "    pca.fit(datos_pca)\n",
    "    # Calcular los vectores y valores propios de la martiz de covarianza\n",
    "    w, v = np.linalg.eig(pca.get_covariance())\n",
    "    # ordenar los valores de mayor a menor\n",
    "    indx = np.argsort(w)[::-1]\n",
    "    # calcular el procentaje de varianza en cada componente\n",
    "    porcentaje = w[indx] / np.sum(w)\n",
    "    # calcular el porcentaje acumulado de los componentes\n",
    "    porcent_acum = np.cumsum(porcentaje)\n",
    "    # encontrar las componentes necesarias para lograr explicar el 90% de variabilidad\n",
    "    pca_90 = np.where(porcent_acum > p_exp)[0][0] + 1\n",
    "\n",
    "    pca = PCA(n_components=pca_90)\n",
    "    datos_pca = datos.iloc[:, 1:]\n",
    "    df1 = datos.iloc[:, 0]\n",
    "    pca.fit(datos_pca)\n",
    "    df2 = pd.DataFrame(pca.transform(datos_pca))\n",
    "\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    r_datos_pca = pd.concat([df1, df2], axis=1)\n",
    "    r_datos_pca.index = datos_pca.index\n",
    "\n",
    "    # Renombrar columnas\n",
    "    r_datos_pca.columns = ['pca_y'] + ['pca_x_' + str(i) for i in range(0, pca_90)]\n",
    "\n",
    "    return r_datos_pca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
